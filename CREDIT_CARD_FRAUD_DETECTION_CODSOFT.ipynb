{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hitanshi08/codsoft/blob/main/CREDIT_CARD_FRAUD_DETECTION_CODSOFT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNXdk1VHzt1l"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEjq4jAbzwjj"
      },
      "source": [
        "IMPORTING DEPENDENCIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUwD5vToyuub"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8NGt0-XRGq8o"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "from scipy.stats import norm , skew\n",
        "from scipy.special import boxcox1p\n",
        "from scipy.stats import boxcox_normmax\n",
        "\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve , auc , roc_auc_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.linear_model import Ridge, Lasso, LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "import xgboost as xgo\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_importance\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "#To ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy-CNBaY8RD3"
      },
      "source": [
        "EXPLORATORY DATA ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEdVAqW088iE"
      },
      "outputs": [],
      "source": [
        "#CHECKING THE SHAPE\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0Juct3L9CJE"
      },
      "outputs": [],
      "source": [
        "#CHECKING THE DATATYPES AND NULL/NON-NULL DISTRIBUTION\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JpvONsR9XKG"
      },
      "outputs": [],
      "source": [
        "#CHECKING NUMERICAL VALUE IN DATASET\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TXST-Di9fX2"
      },
      "outputs": [],
      "source": [
        "#CHECKING THE CLASS DISTRIBUTER OF TARGET VARIABLE\n",
        "df['Class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIQUvOoa90sJ"
      },
      "outputs": [],
      "source": [
        "#CHECKING THE CLASS DISTRIBUTION OF THE TARGET VARIABLE IN PERCENTAGE\n",
        "print((df.groupby('Class')['Class'].count()/df['Class'].count())*100)\n",
        "((df.groupby('Class')['Class'].count()/df['Class'].count())*100).plot.pie()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42c4LuTQ-g0d"
      },
      "outputs": [],
      "source": [
        "#CHECKING THE % DISTRIBUTION OF NORMAL VS FRAUD\n",
        "classes=df['Class'].value_counts()\n",
        "normal_share=classes[0]/df['Class'].count()*100\n",
        "fraud_share=classes[1]/df['Class'].count()*100\n",
        "\n",
        "print(normal_share)\n",
        "print(fraud_share)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sD_MwIXj_NaU"
      },
      "outputs": [],
      "source": [
        "#CREATE A BAR PLOT FOR THE NUMBER AND % OF FRAUDULENT VS NON-FRAUDULENT TRANSACTIONS\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.countplot(df['Class'])\n",
        "plt.title(\"Class Count\" , fontsize=18)\n",
        "plt.xlabel(\"Record counts by Class\", fontsize=15)\n",
        "plt.ylabel(\"Count\", fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COGKOHw_AQwI"
      },
      "outputs": [],
      "source": [
        "#CHECKING THE CORRELATION\n",
        "corr = df.corr()\n",
        "corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovAecJAKAZgO"
      },
      "outputs": [],
      "source": [
        "#CHECKING THE CORRELATION IN HEATMAP\n",
        "plt.figure(figsize=(24,18))\n",
        "\n",
        "sns.heatmap(corr, cmap=\"coolwarm\", annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNVcjLUoA4p6"
      },
      "source": [
        "OBSERVATION OF DISTRIBUTION OF OUR CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pbMMngpA_e5"
      },
      "outputs": [],
      "source": [
        "#As time is given in relative fashion, we are using pandas. Timedelta which represent duration, the difference between two time updates\n",
        "Delta_Time = pd.to_timedelta(df['Time'], unit='s')\n",
        "\n",
        "#Create derived columns min and hours\n",
        "df['Time_Day'] = (Delta_Time.dt.components.days).astype(int)\n",
        "df['Time_Hour'] = (Delta_Time.dt.components.hours).astype(int)\n",
        "df['Time_Min'] = (Delta_Time.dt.components.minutes).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpFqBmvSCJMP"
      },
      "outputs": [],
      "source": [
        "#DROP UNNECESSARY COLUMNS\n",
        "# we will drop Time,as we have derived Day/Hours/Min from Time column\n",
        "df.drop('Time', axis=1, inplace=True)\n",
        "# we will keep only derived column hour as day/min might not be very useful\n",
        "df.drop(['Time_Day', 'Time_Min'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nL5ZRFMLYIp"
      },
      "source": [
        "SPLITTING THE DATA INTO TRAIN AND TEST DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Pv9mf-fLXs3"
      },
      "outputs": [],
      "source": [
        "#SPLITTING DATASET INTO X AND Y\n",
        "y= df['Class']\n",
        "x= df.drop(['Class'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAc4cBheLtow"
      },
      "outputs": [],
      "source": [
        "#CHECKING SOME ROWS OF X\n",
        "x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fFT2eAuL1Yw"
      },
      "outputs": [],
      "source": [
        "#CHECKING SOME ROWS OF Y\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds4ilp23MAd_"
      },
      "outputs": [],
      "source": [
        "#SPLITTING DATASET\n",
        "x_train, x_test, y_train, y_test= train_test_split(x, y, random_state=100, test_size=0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oMBpyMxMbcs"
      },
      "outputs": [],
      "source": [
        "#CHECKING SPREAD OF DATA POST SPLIT\n",
        "print(np.sum(y))\n",
        "print(np.sum(y_train))\n",
        "print(np.sum(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9GGvXN4Ms64"
      },
      "source": [
        "PUTTING THE DISTRIBUTION OF A VARIABLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIr_QgHcMytk"
      },
      "outputs": [],
      "source": [
        "#Accumulating all the column names under one variable\n",
        "cols = list(x.columns.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNnJspsQNFZ-"
      },
      "outputs": [],
      "source": [
        "#PLOT THE HISTOGRAM OF A VARIABLE FROM THE DATASET TO SEE THE SKEWNESS\n",
        "normal_records = df.Class == 0\n",
        "fraud_records = df.Class ==1\n",
        "\n",
        "plt.figure(figsize=(20,60))\n",
        "for n, col in enumerate(cols):\n",
        "  plt.subplot(10,3,n+1)\n",
        "  sns.distplot(x[col][normal_records], color='green')\n",
        "  sns.distplot(x[col][fraud_records], color='red')\n",
        "  plt.title(col, fontsize=17)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZW7admHQ6CO"
      },
      "source": [
        "MODEL BUILDING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mN9-R_fGQ8Bx"
      },
      "outputs": [],
      "source": [
        "#CREATE A DATAFRAME TO STORE RESULTS\n",
        "df_Results = pd.DataFrame(columns=['Methodology', 'Accuracy', 'roc_value', 'threshold'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OQDdaZmTxr4"
      },
      "outputs": [],
      "source": [
        "#CREATED A COMMON FUNCTIONS TO PLOT CONFUSION MATRIX\n",
        "def Plot_confusion_matrix(y_test, pred_test):\n",
        "  cm = confusion_matrix(y_test, pred_test)\n",
        "  plt.clf()\n",
        "  plt.imshow(cm, interpolation='nearest', cmp=plt.cm.Accent)\n",
        "  categoryNames = ['Non-Fraudulent', 'Fraudulent']\n",
        "  plt.title('Confusion Matrix - Test Data')\n",
        "  plt.ylabel('True Label')\n",
        "  plt.xlabel('Predicted Label')\n",
        "  ticks=np.arrange(len(categoryNames))\n",
        "  plt.xticks(ticks, categoryNames, rotation=45)\n",
        "  plt.yticks(ticks, categoryNames)\n",
        "  s=[['TN', 'FP'], ['FN', 'TP']]\n",
        "\n",
        "  for i in range(2):\n",
        "    for j in range(2):\n",
        "      plt.text(j,i, str(s[i][j])+\"=\"+str(cm[i][j]), fontsize=12)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rg0ZAHThEiZ9"
      },
      "outputs": [],
      "source": [
        "#CREATING A COMMON FUNCTION TO FIT AND PREDICT ON A LR MODEL FOR BOTH L1 L2\n",
        "def buildAndRunLogisticModels(df_Results, Methodology, x_train, y_train, x_test, y_test):\n",
        "\n",
        "  #LOGISTIC REGRESSION\n",
        "  from sklearn import linear_model\n",
        "  from sklearn.model_selection import KFold\n",
        "\n",
        "  num_C = list(np.power(10.0, np_arrange(-10,10)))\n",
        "  cv_num = KFold(n_split=10, shuffle=True, random_state=42)\n",
        "\n",
        "  searchCV_l2 = linear_model.LogisticRegressionCV(\n",
        "      Cs=num_C\n",
        "      ,penalty='12'\n",
        "      ,scoring='roc_auc'\n",
        "      ,cv=cv_num\n",
        "      ,random_state=42\n",
        "      ,max_iter=10000\n",
        "      ,fit_intercept=True\n",
        "      ,solver='newton_cg'\n",
        "      ,tol=10\n",
        "  )\n",
        "\n",
        "  searchCV_l1 =  linear_model.LogisticRegressionCV(\n",
        "      Cs=num_C\n",
        "      ,penalty='12'\n",
        "      ,scoring='roc_auc'\n",
        "      ,cv=cv_num\n",
        "      ,random_state=42\n",
        "      ,max_iter=10000\n",
        "      ,fit_intercept=True\n",
        "      ,solver='newton_cg'\n",
        "      ,tol=10\n",
        "  )\n",
        "\n",
        "  searchCV_l1.fit(x_train, y_train)\n",
        "  searchCV_l2.fit(x_train, y_train)\n",
        "  print('Max auc_roc for l1:', searchCV_l1.scores_[1].mean(axis=0).max())\n",
        "  print('Max auc_roc for l2:', searchCV_l2.scores_[1].mean(axis=0).max())\n",
        "\n",
        "  print(\"Parameters for l1 regularizations\")\n",
        "  print(searchCV_l1.coef_)\n",
        "  print(searchCV_l1.intercept_)\n",
        "  print(searchCV_l1.scores_)\n",
        "\n",
        "  print(\"Parameters for l2 regularizations\")\n",
        "  print(searchCV_l2.coef_)\n",
        "  print(searchCV_l2.intercept_)\n",
        "  print(searchCV_l2.scores_)\n",
        "\n",
        "  # FIND PREDICTED VALUES\n",
        "  y_pred_l1 = searchCV_l1.predict(x_test)\n",
        "  y_pred_l2 = searchCV_l2.predict(x_test)\n",
        "\n",
        "  # FIND PREDICTED PROBABILITIES\n",
        "  y_pred_probs_l1 = searchCV_l1.predict_proba(x_test)[:,1]\n",
        "  y_pred_probs_l2 = searchCV_l2.predict_proba(x_test)[:,1]\n",
        "\n",
        "  #ACCURACY OF l2/l1\n",
        "  Accuracy_l2 = metrics.accuracy_score(y_pred=y_pred_l2, y_true=y_test)\n",
        "  Accuracy_l1 = metrics.accuracy_score(y_pred=y_pred_l1, y_true=y_test)\n",
        "\n",
        "  print(\"Accuracy of Logistic model with 12 regularisation : {0}\".format(Accuracy_l2))\n",
        "  print(\"Confusion Matrix\")\n",
        "  Plot_confusion_matrix(y_test, y_pred_l2)\n",
        "  print(\"classification Report\")\n",
        "  print(classification_report(y_test, y_pred_l2))\n",
        "\n",
        "\n",
        "  print(\"Accuracy of Logistic model with 11 regularisation : {0}\".format(Accuracy_l1))\n",
        "  print(\"Confusion Matrix\")\n",
        "  Plot_confusion_matrix(y_test, y_pred_l1)\n",
        "  print(\"classification Report\")\n",
        "  print(classification_report(y_test, y_pred_l1))\n",
        "\n",
        "  l2_roc_value = roc_auc_score(y_test , y_pred_probs_l2)\n",
        "  print(\"l2_roc_value: {0}\".format(l2_roc_value))\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_probs_l2)\n",
        "  threshold = thresholds[np.argmax(tpr.fpr)]\n",
        "  print(\"l2 threshold: {0}\".format(threshold))\n",
        "\n",
        "  roc_auc = metrics.auc(fpr,tpr)\n",
        "  print(\"ROC for the test dataset\",'{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr,tpr,label=\"Test, auc=\"+str(roc_auc))\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "\n",
        "  df_Results = df_Results.append(pd.DataFrame({'Methodology': Methodology, 'Model': 'Logistic Regression with l2 Regularisation', 'Accuracy': Accuracy_l2, 'roc_value': l2_roc_value, 'threshold': threshold}, index=[0]), ignore_index=True)\n",
        "\n",
        "  l1_roc_value = roc_auc_score(y_test , y_pred_probs_l1)\n",
        "  print(\"l1_roc_value: {0}\".format(l2_roc_value))\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_probs_l1)\n",
        "  threshold = thresholds[np.argmax(tpr.fpr)]\n",
        "  print(\"l1 threshold: {0}\".format(threshold))\n",
        "\n",
        "  roc_auc = metrics.auc(fpr,tpr)\n",
        "  print(\"ROC for the test dataset\",'{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr,tpr,label=\"Test, auc=\"+str(roc_auc))\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "\n",
        "  df_Results = df_Results.append(pd.DataFrame({'Methodology': Methodology, 'Model': 'Logistic Regression with l1 Regularisation', 'Accuracy': Accuracy_l1, 'roc_value': l1_roc_value, 'threshold0': threshold}, index=[0]), ignore_index=True)\n",
        "  return df_Results\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64DX4_NYR78s"
      },
      "outputs": [],
      "source": [
        "#CREATED A COMMON FUNCTION TO FIT AND PREDICT ON KNN MODEL\n",
        "def buildAndRunKNNModels(df_Results,Methodology,x_train,y_train,x_test,y_test):\n",
        "\n",
        "  #create KNN model and fit the model with train dataset\n",
        "  knn=KNeighborsClassifier(n_neighbors=5,n_jobs=16)\n",
        "  knn.fit(x_train,y_train)\n",
        "  score=knn.score(x_test,y_test)\n",
        "  print(\"model score\")\n",
        "  print(score)\n",
        "\n",
        "  #Accuracy\n",
        "  y_pred=knn.predict(x_test)\n",
        "  KNN_Accuracy=metrics.accuracy_score(y_pred=y_pred,y_true=y_test)\n",
        "  print(\"Confusion Matrix\")\n",
        "  Plot_confusion_matrix(y_test,y_pred)\n",
        "\n",
        "  knn_probs=knn.predict_proba(x_test)[:,1]\n",
        "\n",
        "  #calculate roc auc\n",
        "  knn_roc_value = roc_auc_score(y_test,knn_probs)\n",
        "  print(\"KNN roc_value:{0}\".format(knn_roc_value))\n",
        "  fpr,tpr,thresholds = metrics.roc_curve(y_test,knn_probs)\n",
        "  threshold=thresholds[np.argmax(tpr.fpr)]\n",
        "  print(\"KNN threshold:{0}\".format(threshold))\n",
        "\n",
        "  roc_auc=metrics.auc(fpr,tpr)\n",
        "  print(\"ROC for the test dataset\",'{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr,tpr,label=\"Test,auc=\"+str(roc_auc))\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "\n",
        "  df_Results=df_Results.append(pd.DataFrame({'Methodology': Methodology,'Model':'KNN','Accuracy':score,'roc_value':knn_roc_value,'threshold':threshold},index=[0]),ignore_index=True)\n",
        "  return df_Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5wz2pRRxXsI"
      },
      "outputs": [],
      "source": [
        "#Created a common function to fit and predict on Tree Models for bothgini and entropy criteria\n",
        "def buildingAndRunTreeModels(df_Results,Methodology,x_train,y_train,x_test,y_test):\n",
        "\n",
        "  #Evaluate Decision Tree model with 'gini' & 'entropy'\n",
        "  criteria = ['gini', 'entropy']\n",
        "  scores={}\n",
        "  for c in criteria:\n",
        "    dt=DecisionTreeClassifier(criterion=c,random_state=42)\n",
        "    dt.fit(x_train,y_train)\n",
        "    y_pred=dt.predict(x_test)\n",
        "    test_score = dt.score(x_test,y_test)\n",
        "    tree_preds = dt.predict_proba(x_test)[:,1]\n",
        "    tree_roc_value = roc_auc_score(y_test,tree_preds)\n",
        "    scores = test_score\n",
        "    print(c + \"score: {0}\".format(test_score))\n",
        "    print(\"Confusion Matrix\")\n",
        "    Plot_confusion_matrix(y_test,y_pred)\n",
        "    print(\"classification report\")\n",
        "    print(classification_report(y_test,y_pred))\n",
        "    print(c + \"tree_roc_value: {0}\".format(tree_roc_value))\n",
        "    fpr,tpr,threshold = metrics.roc_curve(y_test,tree_preds)\n",
        "    threshold = threshold[np.argmax(tpr.fpr)]\n",
        "    print(\"Tree threshold: {0}\".format(threshold))\n",
        "    roc_auc = metrics.auc(fpr,tpr)\n",
        "    print(\"ROC for the test dataset\",'{:.1%}'.format(roc_auc))\n",
        "    plt.legend(loc=4)\n",
        "    plt.show()\n",
        "\n",
        "    df_Results=df_Results.append(pd.DataFrame({'Methodology': Methodology,'Model':'Tree Model with {0} criteria'.format(c),'Accuracy':test_score,'roc_value':tree_roc_value,'threshold':threshold},index=[0]),ignore_index=True)\n",
        "    return df_Results\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DMP0wL-2cu-"
      },
      "outputs": [],
      "source": [
        "#Created a common function to fit and predict on random forest model\n",
        "def buildingAndRunRandomForestModels(df_Results,Methodology,x_train,y_train,x_test,y_test):\n",
        "\n",
        "  #Create model with 100 trees\n",
        "  RF_Model = RandomForestClassifier(n_estimators=100,\n",
        "                                    bootstrap=True,\n",
        "                                    max_features='sqrt',random_state=42)\n",
        "  #fit on training data\n",
        "  RF_Model.fit(x_train,y_train)\n",
        "  RF_test_score=RF_model.score(x_test,y_test)\n",
        "  RF_model.predict(x_test)\n",
        "\n",
        "  print('Model Accuracy:{0}'.format(RF_test_score))\n",
        "\n",
        "  #Actual class predictions\n",
        "  rf_predictions = RF_model.predict(x_test)\n",
        "  print(\"Confusion Matrix\")\n",
        "  Plot_confusion_matrix(y_test,rf_predictions)\n",
        "  print(\"classification report\")\n",
        "  print(classification_report(y_test,rf_predictions))\n",
        "\n",
        "  #Probabilities for each class\n",
        "  rf_probs=RF_model.predict_proba(x_test)[:,1]\n",
        "\n",
        "  #calculate roc auc\n",
        "  roc_value = roc_auc_score(y_test,rf_probs)\n",
        "  print(\"Random Forest roc_value:{0}\".format(roc_value))\n",
        "  fpr,tpr,thresholds = metrics.roc_curve(y_test,rf_probs)\n",
        "  threshold=thresholds[np.argmax(tpr.fpr)]\n",
        "  print(\"Random Forest threshold:{0}\".format(threshold))\n",
        "\n",
        "  roc_auc=metrics.auc(fpr,tpr)\n",
        "  print(\"ROC for the test dataset\",'{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr,tpr,label=\"Test,auc=\"+str(roc_auc))\n",
        "  plt.legend(loc=4)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  df_Results=df_Results.append(pd.DataFrame({'Methodology': Methodology,'Model':'Random Forest','Accuracy':RF_test_score,'roc_value':roc_value,'threshold':threshold},index=[0]),ignore_index=True)\n",
        "  return df_Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F12v85Wk7sDb"
      },
      "outputs": [],
      "source": [
        "#Created a common function to fit and predict on a XGBoost model\n",
        "def buildingAndRunXGBoostModels(df_Results,Methodology,x_train,y_train,x_test,y_test):\n",
        "  #Evaluate XGBoost Model\n",
        "  XGBmodel=XGBClassifier(random_state=42)\n",
        "  XGBmodel.fit(x_train,y_train)\n",
        "  y_pred=XGBmodel.predict(x_test)\n",
        "  XGB_test_score=XGBmodel.score(x_test,y_test)\n",
        "  print('Model_Accuracy:{0}'.format(XGB_test_score))\n",
        "\n",
        "  print(\"Confusion Matrix\")\n",
        "  Plot_confusion_matrix(y_test,y_pred)\n",
        "  print(\"classification report\")\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  XGB_probs=XGBmodel.predict_proba(x_test)[:,1]\n",
        "\n",
        "  roc_value = roc_auc_score(y_test,XGB_probs)\n",
        "  print(\"XGBoost roc_value:{0}\".format(XGB_roc_value))\n",
        "  fpr,tpr,thresholds = metrics.roc_curve(y_test,XGB_probs)\n",
        "  threshold=thresholds[np.argmax(tpr.fpr)]\n",
        "  print(\"XGBoost threshold:{0}\".format(threshold))\n",
        "\n",
        "  roc_auc=metrics.auc(fpr,tpr)\n",
        "  print(\"ROC for the test dataset\",'{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr,tpr,label=\"Test,auc=\"+str(roc_auc))\n",
        "  plt.legend(loc=4)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  df_Results=df_Results.append(pd.DataFrame({'Methodology': Methodology,'Model':'XGBoost','Accuracy':XGB_test_score,'roc_value':XGB_roc_value,'threshold':threshold},index=[0]),ignore_index=True)\n",
        "  return df_Results\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE1V3qcb-l54"
      },
      "outputs": [],
      "source": [
        "#created a common function to fit and predict on SVM model\n",
        "def buildingAndRunSVMModels(df_Results,Methodology,x_train,y_train,x_test,y_test):\n",
        "  from sklearn.svm import SVC\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "\n",
        "  cif=SVC(kernel='sigmoid',random_state=42)\n",
        "  cif.fit(x_train,y_train)\n",
        "  y_pred_SVM=cif.predict(x_test)\n",
        "  SVM_score=accuracy.score(y_test,y_pred_SVM)\n",
        "  print('Accuracy_score:{0}'.format(SVM_score))\n",
        "\n",
        "  print(\"Confusion Matrix\")\n",
        "  Plot_confusion_matrix(y_test,y_pred_SVM)\n",
        "  print(\"classification report\")\n",
        "  print(classification_report(y_test,y_pred_SVM))\n",
        "\n",
        "  #run classifier\n",
        "  classifier=SVC(kernel='sigmoid' , probability=True)\n",
        "  svm_probs=classifier.fit(x_train,y_train).predict_proba(x_test)[:,1]\n",
        "  roc_value = roc_auc_score(y_test,svm_probs)\n",
        "  print(\"SVM roc_value:{0}\".format(roc_value))\n",
        "  fpr,tpr,thresholds = metrics.roc_curve(y_test,svm_probs)\n",
        "  threshold=thresholds[np.argmax(tpr.fpr)]\n",
        "  print(\"XGBoost threshold:{0}\".format(threshold))\n",
        "\n",
        "  roc_auc=metrics.auc(fpr,tpr)\n",
        "  print(\"ROC for the test dataset\",'{:.1%}'.format(roc_auc))\n",
        "  plt.plot(fpr,tpr,label=\"Test,auc=\"+str(roc_auc))\n",
        "  plt.legend(loc=4)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  df_Results=df_Results.append(pd.DataFrame({'Methodology': Methodology,'Model':'SVM','Accuracy':SVM_test_score,'roc_value':roc_value,'threshold':threshold},index=[0]),ignore_index=True)\n",
        "  return df_Results\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXDDgTOcBOAH"
      },
      "source": [
        "PERFORM CROSS VALIDATION WITH REPEATKFOLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oclh0KX7BS9r"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RepeatedKFold\n",
        "rkf=RepeatedKFold(n_splits=5,n_repeats=10,random_state=None)\n",
        "for train_index,test_index in rkf.split(x,y):\n",
        "  print(\"TRAIN:\",train_index,\"TEST:\",test_index)\n",
        "  x_train_cv,x_test_cv=x.iloc[train_index],x.iloc[test_index]\n",
        "  y_train_cv,y_test_cv=y.iloc[train_index],y.iloc[test_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KljQQx42Cldw"
      },
      "outputs": [],
      "source": [
        "# Run Logistic Regression with l1 and l2 Regularisation\n",
        "def buildAndRunLogisticModels(df_Results, model_name, x_train, y_train, x_test, y_test):\n",
        "  print(\"Logistic Regression with L1 and L2 Regularisation\")\n",
        "  start_time = time.time()\n",
        "  df_Results = buildAndRunLogisticModels(df_Results,\"RepeatedKFold Cross Validation\", x_train_cv,y_train_cv, x_test_cv,y_test_cv)\n",
        "  print(\"Time Taken by Model: ---%s seconds ---\"% (time.time() - start_time))\n",
        "  print('-'*60 )\n",
        "\n",
        "# Run KNN Model\n",
        "  print(\"KNN Model\")\n",
        "  start_time = time.time()\n",
        "  df_Results = buildAndRunLogisticModels(df_Results,\"RepeatedKFold Cross Validation\", x_train_cv,y_train_cv, x_test_cv,y_test_cv)\n",
        "  print(\"Time Taken by Model: ---%s seconds ---\"% (time.time() - start_time))\n",
        "  print('-'*60 )\n",
        "\n",
        "#Run Decision Tree Models with 'gini' & 'entropy' criteria\n",
        "  print(\"Decision Tree Models with 'gini' & 'entropy' criteria\")\n",
        "  start_time = time.time()\n",
        "  df_Results = buildAndRunLogisticModels(df_Results,\"RepeatedKFold Cross Validation\", x_train_cv,y_train_cv, x_test_cv,y_test_cv)\n",
        "  print(\"Time Taken by Model: ---%s seconds ---\"% (time.time() - start_time))\n",
        "  print('-'*60 )\n",
        "\n",
        "#Run Random Forest Model\n",
        "  print(\"Random Forest Model\")\n",
        "  start_time = time.time()\n",
        "  df_Results = buildAndRunLogisticModels(df_Results,\"RepeatedKFold Cross Validation\", x_train_cv,y_train_cv, x_test_cv,y_test_cv)\n",
        "  print(\"Time Taken by Model: ---%s seconds ---\"% (time.time() - start_time))\n",
        "  print('-'*60 )\n",
        "\n",
        "#Run XGBoost Model\n",
        "  print(\"XGBoost Model\")\n",
        "  start_time = time.time()\n",
        "  df_Results = buildAndRunLogisticModels(df_Results,\"RepeatedKFold Cross Validation\", x_train_cv,y_train_cv, x_test_cv,y_test_cv)\n",
        "  print(\"Time Taken by Model: ---%s seconds ---\"% (time.time() - start_time))\n",
        "  print('-'*60 )\n",
        "\n",
        "#Run SVM Model\n",
        "  print(\"SVM Model with Sigmoid Kernel\")\n",
        "  start_time = time.time()\n",
        "  df_Results = buildAndRunLogisticModels(df_Results,\"RepeatedKFold Cross Validation\", x_train_cv,y_train_cv, x_test_cv,y_test_cv)\n",
        "  print(\"Time Taken by Model: ---%s seconds ---\"% (time.time() - start_time))\n",
        "  print('-'*60 )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXQD4w7dMT2K"
      },
      "outputs": [],
      "source": [
        "df_Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYpxEqqoMcXq"
      },
      "source": [
        "PERFORM CROSS VALIDATION WITH STRATIFIEDKFOLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DljMVpnSMjR-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=5, random_state=None, shuffle=True)\n",
        "y_imputer = SimpleImputer(strategy=\"mean\")\n",
        "y_imputed = y_imputer.fit_transform(y.values.reshape(-1, 1))\n",
        "y = pd.Series(y_imputed.flatten())\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, random_state=None)\n",
        "for train_index, test_index in kf.split(x,y):\n",
        "  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "  x_train_SKF_cv, x_test_SKF_cv = x.iloc[train_index], x.iloc[test_index]\n",
        "  y_train_SKF_cv, y_test_SKF_cv = y.iloc[train_index], y.iloc[test_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_GsJCe6N8NE"
      },
      "outputs": [],
      "source": [
        "# Run Logistic Regression with l1 and l2 Regularisation\n",
        "def buildAndRunLogisticModels(df_Results, model_name, x_train, y_train, x_test, y_test):\n",
        "  print(\"Logistic Regression with L1 and L2 Regularisation\")\n",
        "  start_time = time.time()\n",
        "  df_Results = buildAndRunLogisticModels(df_Results,\"StratifiedKFold Cross Validation\", x_train_cv,y_train_cv, x_test_cv,y_test_cv)\n",
        "  print(\"Time Taken by Model: ---%s seconds ---\"% (time.time() - start_time))\n",
        "  print('-'*60 )\n",
        "\n",
        "# Run KNN Model\n",
        "  print(\"KNN Model\")\n",
        "  start_time = time.time()\n",
        "  df_Results = buildAndRunLogisticModels(df_Results,\"StratifiedKFold Cross Validation\", x_train_cv,y_train_cv, x_test_cv,y_test_cv)\n",
        "  print(\"Time Taken by Model: ---%s seconds ---\"% (time.time() - start_time))\n",
        "  print('-'*60 )\n",
        "\n",
        "#Run Decision Tree Models with 'gini' & 'entropy' criteria\n",
        "  print(\"Decision Tree Models with 'gini' & 'entropy' criteria\")\n",
        "  start_time = time.time()\n",
        "  df_Results = buildAndRunLogisticModels(df_Results,\"StratifiedKFold Cross Validation\", x_train_cv,y_train_cv, x_test_cv,y_test_cv)\n",
        "  print(\"Time Taken by Model: ---%s seconds ---\"% (time.time() - start_time))\n",
        "  print('-'*60 )\n",
        "\n",
        "#Run Random Forest Model\n",
        "  print(\"Random Forest Model\")\n",
        "  start_time = time.time()\n",
        "  df_Results = buildAndRunLogisticModels(df_Results,\"StratifiedKFold Cross Validation\", x_train_cv,y_train_cv, x_test_cv,y_test_cv)\n",
        "  print(\"Time Taken by Model: ---%s seconds ---\"% (time.time() - start_time))\n",
        "  print('-'*60 )\n",
        "\n",
        "#Run XGBoost Model\n",
        "  print(\"XGBoost Model\")\n",
        "  start_time = time.time()\n",
        "  df_Results = buildAndRunLogisticModels(df_Results,\"StratifiedKFold Cross Validation\", x_train_cv,y_train_cv, x_test_cv,y_test_cv)\n",
        "  print(\"Time Taken by Model: ---%s seconds ---\"% (time.time() - start_time))\n",
        "  print('-'*60 )\n",
        "\n",
        "#Run SVM Model\n",
        "  print(\"SVM Model with Sigmoid Kernel\")\n",
        "  start_time = time.time()\n",
        "  df_Results = buildAndRunLogisticModels(df_Results,\"StratifiedKFold Cross Validation\", x_train_cv,y_train_cv, x_test_cv,y_test_cv)\n",
        "  print(\"Time Taken by Model: ---%s seconds ---\"% (time.time() - start_time))\n",
        "  print('-'*60 )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEyDZxt9U5oR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load data from CSV file (replace 'data.csv' with your actual file path)\n",
        "data = pd.read_csv('/content/creditcard.csv')\n",
        "\n",
        "\n",
        "x_train_SKF_cv = data[['Amount', 'Time'] ].values\n",
        "\n",
        "\n",
        "y_train_SKF_cv = data['Class'].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train_SKF_cv)\n",
        "\n",
        "\n",
        "# Handling Missing Values with Imputation\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "x_train_imputed = imputer.fit_transform(x_train_SKF_cv)\n",
        "\n",
        "\n",
        "# Standard Scaling\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train_imputed)\n",
        "\n",
        "\n",
        "# KFold for Cross-Validation\n",
        "kf = KFold(n_splits=5, random_state=None, shuffle=True)\n",
        "cv_num = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "num_C = list(np.power(10.0, np.arange(-10, 11)))\n",
        "\n",
        "# Logistic Regression with Cross-Validation\n",
        "clf = linear_model.LogisticRegressionCV(\n",
        "    Cs=num_C,\n",
        "    penalty='l2',\n",
        "    scoring='roc_auc',\n",
        "    cv=cv_num,\n",
        "    random_state=42,\n",
        "    max_iter=10000,\n",
        "    fit_intercept=True,\n",
        "    solver='newton-cg',\n",
        "    tol=1e-10,\n",
        "    multi_class='ovr'\n",
        ")\n",
        "\n",
        "clf.fit(x_train_imputed, y_train_encoded)  # Use imputed data for training\n",
        "\n",
        "\n",
        "# Model Evaluation\n",
        "y_pred_probs_l2 = clf.predict_proba(x_test_scaled)[:, 1]\n",
        "y_pred_l2 = clf.predict(x_test_scaled)\n",
        "\n",
        "# Accuracy\n",
        "Accuracy_l2 = accuracy_score(y_pred=y_pred_l2, y_true=y_test)\n",
        "print(\"Accuracy of Logistic model with l2 regularization: {0}\".format(Accuracy_l2))\n",
        "\n",
        "# ROC AUC\n",
        "l2_roc_value = roc_auc_score(y_test, y_pred_probs_l2)\n",
        "print(\"l2 roc_value: {0}\".format(l2_roc_value))\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs_l2)\n",
        "threshold = thresholds[np.argmax(tpr - fpr)]\n",
        "print(\"l2 threshold: {0}\".format(threshold))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxlaJfgEX8vF"
      },
      "outputs": [],
      "source": [
        "clf.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JS9M0lZYX_3k"
      },
      "outputs": [],
      "source": [
        "coefficients = pd.concat([pd.DataFrame(x.columns), pd.DataFrame(np.transpose(clf.coef_))], axis=1)\n",
        "coefficients.columns = ['Feature','Importance Coefficient']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGj8u_55YmJt"
      },
      "outputs": [],
      "source": [
        "coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCTo6Xc9Yr3W"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "sns.barplot(x='Feature', y='Importance coefficient', data=coefficients)\n",
        "plt.title(\"Logistic Regression with l2 regularisation feature importance\", fontsize=18)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4amGpFnnZX1C"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import stratifiedKFold\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, random_state=None)\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(x,y),1):\n",
        "  x_train = x.loc[train_index]\n",
        "  y_train = y.loc[train_index]\n",
        "  x_test = x.loc[test_index]\n",
        "  y_test = x.loc[train_index]\n",
        "  ROS=RandomOverSampler(sampling_strategy=0.5)\n",
        "  x_over, y_over= ROS.fit_resample(x_train, y_train)\n",
        "\n",
        "  x_over = pd.DataFrame(data=x_over, columns=cols)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4Fifnw3gIXL"
      },
      "outputs": [],
      "source": [
        "Data_Imbalance_Handling = \"RandomOversampling with StratifiedKFold CV\"\n",
        "print(\"Logistic Regression with l1 and l2 regularisation\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModel(df_Results, Data_Imbalance_Handling, x_over, y_over, x_test, y_test)\n",
        "print(\"Time Taken by Model:---%s seconds---\"%(time.time() - start_time))\n",
        "print('-'*60)\n",
        "\n",
        "print(\"KNN Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModel(df_Results, Data_Imbalance_Handling, x_over, y_over, x_test, y_test)\n",
        "print(\"Time Taken by Model:---%s seconds---\"%(time.time() - start_time))\n",
        "print('-'*60)\n",
        "\n",
        "print(\"Decision Tree Models with 'gini' and 'entropy' criteria\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModel(df_Results, Data_Imbalance_Handling, x_over, y_over, x_test, y_test)\n",
        "print(\"Time Taken by Model:---%s seconds---\"%(time.time() - start_time))\n",
        "print('-'*60)\n",
        "\n",
        "print(\"Random Forest Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModel(df_Results, Data_Imbalance_Handling, x_over, y_over, x_test, y_test)\n",
        "print(\"Time Taken by Model:---%s seconds---\"%(time.time() - start_time))\n",
        "print('-'*60)\n",
        "\n",
        "print(\"XGBoost Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModel(df_Results, Data_Imbalance_Handling, x_over, y_over, x_test, y_test)\n",
        "print(\"Time Taken by Model:---%s seconds---\"%(time.time() - start_time))\n",
        "print('-'*60)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTyF77gQjNqP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import stratifiedKFold\n",
        "from imblearn import over_sampling\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, random_state=None)\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(x,y),1):\n",
        "  x_train = x.loc[train_index]\n",
        "  y_train = y.loc[train_index]\n",
        "  x_test = x.loc[test_index]\n",
        "  y_test = x.loc[train_index]\n",
        "  SMOTE=over_sampling.SMOTE(random_state=0)\n",
        "  x_train_Smote, y_train_Smote= SMOTE.fit_resample(x_train, y_train)\n",
        "\n",
        "  x_train_Smote = pd.DataFrame(data=x_train_Smote, columns=cols)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dw8V3bJHjzqe"
      },
      "outputs": [],
      "source": [
        "Data_Imbalance_Handling = \"SMOTE Oversampling with StratifiedKFold CV\"\n",
        "print(\"Logistic Regression with l1 and l2 regularisation\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModel(df_Results, Data_Imbalance_Handling, x_train_Smote, y_train_Smote, x_test, y_test)\n",
        "print(\"Time Taken by Model:---%s seconds---\"%(time.time() - start_time))\n",
        "print('-'*80)\n",
        "\n",
        "print(\"KNN Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModel(df_Results, Data_Imbalance_Handling, x_train_Smote, y_train_Smote, x_test, y_test)\n",
        "print(\"Time Taken by Model:---%s seconds---\"%(time.time() - start_time))\n",
        "print('-'*80)\n",
        "\n",
        "print(\"Decision Tree Models with 'gini' and 'entropy' criteria\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModel(df_Results, Data_Imbalance_Handling, x_train_Smote, y_train_Smote, x_test, y_test)\n",
        "print(\"Time Taken by Model:---%s seconds---\"%(time.time() - start_time))\n",
        "print('-'*80)\n",
        "\n",
        "print(\"Random Forest Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModel(df_Results, Data_Imbalance_Handling, x_train_Smote, y_train_Smote, x_test, y_test)\n",
        "print(\"Time Taken by Model:---%s seconds---\"%(time.time() - start_time))\n",
        "print('-'*80)\n",
        "\n",
        "print(\"XGBoost Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModel(df_Results, Data_Imbalance_Handling, x_train_Smote, y_train_Smote, x_test, y_test)\n",
        "print(\"Time Taken by Model:---%s seconds---\"%(time.time() - start_time))\n",
        "print('-'*80)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_exrBg3EkZLY"
      },
      "outputs": [],
      "source": [
        "df_Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU9ywqivka_H"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import stratifiedKFold\n",
        "from imblearn import over_sampling\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, random_state=None)\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(x,y),1):\n",
        "  x_train = x.loc[train_index]\n",
        "  y_train = y.loc[train_index]\n",
        "  x_test = x.loc[test_index]\n",
        "  y_test = x.loc[train_index]\n",
        "  ADASYN=over_sampling.SMOTE(random_state=0)\n",
        "  x_train_ADASYN, y_train_ADASYN= ADASYN.fit_resample(x_train, y_train)\n",
        "\n",
        "  x_train_ADASYN = pd.DataFrame(data=x_train_ADASYN, columns=cols)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaGOy3DHk2P_"
      },
      "outputs": [],
      "source": [
        "Data_Imbalance_Handling = \"ADASYN Oversampling with StratifiedKFold CV\"\n",
        "print(\"Logistic Regression with l1 and l2 regularisation\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModel(df_Results, Data_Imbalance_Handling, x_train_ADASYN, y_train_ADASYN, x_test, y_test)\n",
        "print(\"Time Taken by Model:---%s seconds---\"%(time.time() - start_time))\n",
        "print('-'*80)\n",
        "\n",
        "print(\"KNN Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModel(df_Results, Data_Imbalance_Handling, x_train_ADASYN, y_train_ADASYN, x_test, y_test)\n",
        "print(\"Time Taken by Model:---%s seconds---\"%(time.time() - start_time))\n",
        "print('-'*80)\n",
        "\n",
        "print(\"Decision Tree Models with 'gini' and 'entropy' criteria\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModel(df_Results, Data_Imbalance_Handling, x_train_ADASYN, y_train_ADASYN, x_test, y_test)\n",
        "print(\"Time Taken by Model:---%s seconds---\"%(time.time() - start_time))\n",
        "print('-'*80)\n",
        "\n",
        "print(\"Random Forest Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModel(df_Results, Data_Imbalance_Handling, x_train_ADASYN, y_train_ADASYN, x_test, y_test)\n",
        "print(\"Time Taken by Model:---%s seconds---\"%(time.time() - start_time))\n",
        "print('-'*80)\n",
        "\n",
        "print(\"XGBoost Model\")\n",
        "start_time = time.time()\n",
        "df_Results = buildAndRunLogisticModel(df_Results, Data_Imbalance_Handling, x_train_ADASYN, y_train_ADASYN, x_test, y_test)\n",
        "print(\"Time Taken by Model:---%s seconds---\"%(time.time() - start_time))\n",
        "print('-'*80)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVCy_ccxlgYo"
      },
      "outputs": [],
      "source": [
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "param_test={\n",
        "    'max_depth':range(3,10,2),\n",
        "    'min_child_weight':range(1,6,2),\n",
        "    'n_estimators':range(60,130,150),\n",
        "    'learning_rate':range(0.05,0.1,0.125,0.15,0.2),\n",
        "    'subsample':[i/10.0 for i in range(7,10)],\n",
        "    'gamma':[i/10.0 for i in range(0,5)],\n",
        "    'colsample_bytree':[i/10.0 for i in range(7,10)]\n",
        "\n",
        "}\n",
        "\n",
        "gsearch1 = RandomizedSearchCV(estimator = XGBClassifier(base_score=0.5,booster='gbtree',colsample_bylevel=1,\n",
        "                                                        colsample_bynode=1,max_delta_step=0,\n",
        "                                                        missing=None, n_jobs=-1,\n",
        "                                                        nthread=None, objective='binary:logistic',random_state=42,\n",
        "                                                        reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "                                                        silent=None, verbosity=1),\n",
        "                                                        param_distribution=param_test, n_iter=5, scoring='roc_auc',n_jobs=-1, cv=5)\n",
        "\n",
        "gsearch1.fit(x_over, y_over)\n",
        "gsearch1.cv_results, gsearch1.best_params_,gsearch1.best_score_\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmEWSYz_o_zM"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "clf=XGBClassifier(base_score=0.5, booster='gbtree',colsample_bylevel=1,\n",
        "                  colsample_bynode=1,colsample_bytree=0.7, gamma=0.2,\n",
        "                  learning_rate=0.125, missing=None, n_estimators=60,n_jobs=1,\n",
        "                  min_child_weight=5,missing=None,n_estimators=60,n_jobs=1,\n",
        "                  mthread=None,objective='binary.logistic',random_state=42,\n",
        "                  reg_alpha=0,reg_lambda=1,scale_pos_weight=1,seed=None,\n",
        "                  silent=None,subsample=0.8,verbosity=1)\n",
        "\n",
        "clf.fit(x_over,y_over)\n",
        "XGB_test_score=clf.score(x_test,y_test)\n",
        "print('Model Accuracy:{0}'.format(XGB_test_score))\n",
        "XGB_roc_value=roc_auc_score(y_test,XGB_probs)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiPZy3cTs1DTJP4lJGQVZ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}